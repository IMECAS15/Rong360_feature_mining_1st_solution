{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, f1_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import category_encoders as ce\n",
    "import pickle\n",
    "from sklearn.svm import SVC\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/sample_train.txt\", delimiter=\"\\t\")\n",
    "test = pd.read_csv(\"../data/test_id.txt\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train, test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk = pd.read_csv(\"../features/risk/risk.csv\")\n",
    "df = df.merge(risk, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = pd.read_csv(\"../features/symbol/symbol.csv\")\n",
    "df = df.merge(symbol, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dp_emb = pd.read_csv(\"../features/graph/graph_filtered_64.emb\")\n",
    "# df = df.merge(dp_emb, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_emb = pd.read_csv(\"../features/graph/deepwalk_192_filtered.emb\")\n",
    "df = df.merge(dp_emb, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28442, 193)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nv_emb = pd.read_csv(\"../data/edge/node2vec_64.emb\")\n",
    "# df = df.merge(nv_emb, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_info = pd.read_csv(\"../features/graph/graph_info.csv\")\n",
    "df = df.merge(graph_info, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# app_pca = pd.read_csv(\"../data/app/app_pca_16.csv\")\n",
    "# df = df.merge(app_pca, on=\"id\", how=\"left\")\n",
    "\n",
    "app_lda = pd.read_csv(\"../features/app/app_lda_16.csv\")\n",
    "df = df.merge(app_lda, on=\"id\", how=\"left\")\n",
    "\n",
    "# app_lda = pd.read_csv(\"../data1/app/app_lda_16.csv\")\n",
    "# df = df.merge(app_lda, on=\"id\", how=\"left\")\n",
    "\n",
    "# app_nmf = pd.read_csv(\"../data/app/app_nmf_16.csv\")\n",
    "# df = df.merge(app_nmf, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# app_info = pd.read_csv(\"../features/app/app_info.csv\")\n",
    "# df = df.merge(app_info, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "app_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_pca = pd.read_csv(\"../features/app_graph/to_app_pca_mean.csv\")\n",
    "# from_pca = pd.read_csv(\"../features/app_graph/from_app_pca_mean.csv\")\n",
    "\n",
    "# df = df.merge(to_pca, on=\"id\", how=\"left\")\n",
    "# df = df.merge(from_pca, on=\"id\", how=\"left\")\n",
    "\n",
    "to_pca = pd.read_csv(\"../features/app_graph/to_app_pca_num_mean.csv\")\n",
    "from_pca = pd.read_csv(\"../features/app_graph/from_app_pca_num_mean.csv\")\n",
    "\n",
    "df = df.merge(to_pca, on=\"id\", how=\"left\")\n",
    "df = df.merge(from_pca, on=\"id\", how=\"left\")\n",
    "\n",
    "to_pca = pd.read_csv(\"../features/app_graph/to_app_pca_weight_mean.csv\")\n",
    "from_pca = pd.read_csv(\"../features/app_graph/from_app_pca_weight_mean.csv\")\n",
    "\n",
    "df = df.merge(to_pca, on=\"id\", how=\"left\")\n",
    "df = df.merge(from_pca, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_pca_nmf = pd.read_csv(\"../features/app_graph/to_app_nmf_mean.csv\")\n",
    "# from_pca_nmf = pd.read_csv(\"../features/app_graph/from_app_nmf_mean.csv\")\n",
    "\n",
    "# df = df.merge(to_pca_nmf, on=\"id\", how=\"left\")\n",
    "# df = df.merge(from_pca_nmf, on=\"id\", how=\"left\")\n",
    "\n",
    "# to_pca_nmf = pd.read_csv(\"../features/app_graph/to_app_nmf_num_mean.csv\")\n",
    "# from_pca_nmf = pd.read_csv(\"../features/app_graph/from_app_nmf_num_mean.csv\")\n",
    "\n",
    "# df = df.merge(to_pca_nmf, on=\"id\", how=\"left\")\n",
    "# df = df.merge(from_pca_nmf, on=\"id\", how=\"left\")\n",
    "\n",
    "# to_pca_nmf = pd.read_csv(\"../features/app_graph/to_app_nmf_weight_mean.csv\")\n",
    "# from_pca_nmf = pd.read_csv(\"../features/app_graph/from_app_nmf_weight_mean.csv\")\n",
    "\n",
    "# df = df.merge(to_pca_nmf, on=\"id\", how=\"left\")\n",
    "# df = df.merge(from_pca_nmf, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_lda = pd.read_csv(\"../features/app_graph/to_app_lda_mean.csv\")\n",
    "# from_lda = pd.read_csv(\"../features/app_graph/from_app_lda_mean.csv\")\n",
    "\n",
    "# df = df.merge(to_lda, on=\"id\", how=\"left\")\n",
    "# df = df.merge(from_lda, on=\"id\", how=\"left\")\n",
    "\n",
    "# to_lda = pd.read_csv(\"../features/app_graph/to_app_lda_num_mean.csv\")\n",
    "# from_lda = pd.read_csv(\"../features/app_graph/from_app_lda_num_mean.csv\")\n",
    "\n",
    "# df = df.merge(to_lda, on=\"id\", how=\"left\")\n",
    "# df = df.merge(from_lda, on=\"id\", how=\"left\")\n",
    "\n",
    "# to_lda = pd.read_csv(\"../features/app_graph/to_app_lda_weight_mean.csv\")\n",
    "# from_lda = pd.read_csv(\"../features/app_graph/from_app_lda_weight_mean.csv\")\n",
    "\n",
    "# df = df.merge(to_lda, on=\"id\", how=\"left\")\n",
    "# df = df.merge(from_lda, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "risk_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_risk = pd.read_csv(\"../features/risk_graph/to_risk_mean.csv\")\n",
    "# from_risk = pd.read_csv(\"../features/risk_graph/from_risk_mean.csv\")\n",
    "\n",
    "# df = df.merge(to_risk, on=\"id\", how=\"left\")\n",
    "# df = df.merge(from_risk, on=\"id\", how=\"left\")\n",
    "\n",
    "to_risk = pd.read_csv(\"../features/risk_graph/to_risk_num_mean.csv\")\n",
    "from_risk = pd.read_csv(\"../features/risk_graph/from_risk_num_mean.csv\")\n",
    "\n",
    "df = df.merge(to_risk, on=\"id\", how=\"left\")\n",
    "df = df.merge(from_risk, on=\"id\", how=\"left\")\n",
    "\n",
    "to_risk = pd.read_csv(\"../features/risk_graph/to_risk_weight_mean.csv\")\n",
    "from_risk = pd.read_csv(\"../features/risk_graph/from_risk_weight_mean.csv\")\n",
    "\n",
    "df = df.merge(to_risk, on=\"id\", how=\"left\")\n",
    "df = df.merge(from_risk, on=\"id\", how=\"left\")\n",
    "\n",
    "# to_risk = pd.read_csv(\"../features/risk_graph/to_risk_sum.csv\")\n",
    "# from_risk = pd.read_csv(\"../features/risk_graph/from_risk_sum.csv\")\n",
    "\n",
    "# df = df.merge(to_risk, on=\"id\", how=\"left\")\n",
    "# df = df.merge(from_risk, on=\"id\", how=\"left\")\n",
    "\n",
    "to_risk = pd.read_csv(\"../features/risk_graph/to_risk_num_sum.csv\")\n",
    "from_risk = pd.read_csv(\"../features/risk_graph/from_risk_num_sum.csv\")\n",
    "\n",
    "df = df.merge(to_risk, on=\"id\", how=\"left\")\n",
    "df = df.merge(from_risk, on=\"id\", how=\"left\")\n",
    "\n",
    "to_risk = pd.read_csv(\"../features/risk_graph/to_risk_weight_sum.csv\")\n",
    "from_risk = pd.read_csv(\"../features/risk_graph/from_risk_weight_sum.csv\")\n",
    "\n",
    "df = df.merge(to_risk, on=\"id\", how=\"left\")\n",
    "df = df.merge(from_risk, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "symbol_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_cat_num = pd.read_csv(\"../features/symbol_graph/to_symbol_sum.csv\")\n",
    "# from_cat_num = pd.read_csv(\"../features/symbol_graph/from_symbol_sum.csv\")\n",
    "\n",
    "# df = df.merge(to_cat_num, on=\"id\", how=\"left\")\n",
    "# df = df.merge(from_cat_num, on=\"id\", how=\"left\")\n",
    "\n",
    "# to_cat_num = pd.read_csv(\"../features/symbol_graph/to_symbol_num_sum.csv\")\n",
    "# from_cat_num = pd.read_csv(\"../features/symbol_graph/from_symbol_num_sum.csv\")\n",
    "\n",
    "# df = df.merge(to_cat_num, on=\"id\", how=\"left\")\n",
    "# df = df.merge(from_cat_num, on=\"id\", how=\"left\")\n",
    "\n",
    "# to_cat_weight = pd.read_csv(\"../features/symbol_graph/to_symbol_weight_sum.csv\")\n",
    "# from_cat_weight = pd.read_csv(\"../features/symbol_graph/from_symbol_weight_sum.csv\")\n",
    "\n",
    "# df = df.merge(to_cat_weight, on=\"id\", how=\"left\")\n",
    "# df = df.merge(from_cat_weight, on=\"id\", how=\"left\")\n",
    "\n",
    "# to_cat_num = pd.read_csv(\"../features/symbol_graph/to_symbol_mean.csv\")\n",
    "# from_cat_num = pd.read_csv(\"../features/symbol_graph/from_symbol_mean.csv\")\n",
    "\n",
    "# df = df.merge(to_cat_num, on=\"id\", how=\"left\")\n",
    "# df = df.merge(from_cat_num, on=\"id\", how=\"left\")\n",
    "\n",
    "to_cat_num = pd.read_csv(\"../features/symbol_graph/to_symbol_num_mean.csv\")\n",
    "from_cat_num = pd.read_csv(\"../features/symbol_graph/from_symbol_num_mean.csv\")\n",
    "\n",
    "df = df.merge(to_cat_num, on=\"id\", how=\"left\")\n",
    "df = df.merge(from_cat_num, on=\"id\", how=\"left\")\n",
    "\n",
    "to_cat_weight = pd.read_csv(\"../features/symbol_graph/to_symbol_weight_mean.csv\")\n",
    "from_cat_weight = pd.read_csv(\"../features/symbol_graph/from_symbol_weight_mean.csv\")\n",
    "\n",
    "df = df.merge(to_cat_weight, on=\"id\", how=\"left\")\n",
    "df = df.merge(from_cat_weight, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dp_knn = pd.read_csv(\"../features/knn/dp_knn_3.csv\")\n",
    "# df = df.merge(dp_knn, on=\"id\", how=\"left\")\n",
    "\n",
    "# dp_knn = pd.read_csv(\"../features/knn/dp_knn_10.csv\")\n",
    "# df = df.merge(dp_knn, on=\"id\", how=\"left\")\n",
    "\n",
    "# dp_knn = pd.read_csv(\"../features/knn/dp_knn_30.csv\")\n",
    "# df = df.merge(dp_knn, on=\"id\", how=\"left\")\n",
    "\n",
    "# dp_knn = pd.read_csv(\"../features/knn/dp_knn_100.csv\")\n",
    "# df = df.merge(dp_knn, on=\"id\", how=\"left\")\n",
    "\n",
    "# dp_knn = pd.read_csv(\"../features/knn/dp_knn_300.csv\")\n",
    "# df = df.merge(dp_knn, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "中心性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = pd.read_csv(\"../features/graph/pagerank.csv\")\n",
    "df = df.merge(pr, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in [\"to\", \"from\"]:\n",
    "    for w in ['', '_num', '_weight']:\n",
    "        for f in ['sum', 'mean']:\n",
    "            a = pd.read_csv(\"../features/graph/%s_pagerank%s_%s.csv\" % (d, w, f))\n",
    "            df = df.merge(a, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = pd.read_csv(\"../features/graph/hits.csv\")\n",
    "df = df.merge(hits, on=\"id\", how=\"left\")\n",
    "\n",
    "for d in [\"to\", \"from\"]:\n",
    "    for w in ['', '_num', '_weight']:\n",
    "        for f in ['sum', 'mean']:\n",
    "            a = pd.read_csv(\"../features/graph/%s_hits%s_%s.csv\" % (d, w, f))\n",
    "            df = df.merge(a, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二度联系人"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 联系人个数\n",
    "for d1 in [\"from\", \"to\"]:\n",
    "    for d2 in [\"from\", \"to\"]:\n",
    "        for t in [\"\", \"_num\", \"_weight\"]:\n",
    "            for f in [\"sum\", \"mean\"]:\n",
    "                a = pd.read_csv(\"../features/graph/%s_d2_%s%s_%s.csv\" % (d1, d2, t, f))\n",
    "                df = df.merge(a, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 二度联系人PageRank值\n",
    "for d1 in [\"from\", \"to\"]:\n",
    "    for d2 in [\"from\", \"to\"]:\n",
    "        for t in [\"num\", \"weight\"]:\n",
    "            for f in [\"mean\"]:\n",
    "                a = pd.read_csv(\"../features/graph/%s_pg_%s_%s_%s_%s_%s.csv\" % (d1, d2, t, f, t, f))\n",
    "                df = df.merge(a, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for d1 in [\"from\", \"to\"]:\n",
    "#     for d2 in [\"from\", \"to\"]:\n",
    "#         for t in [\"num\", \"weight\"]:\n",
    "#             for f in [\"sum\", \"mean\"]:\n",
    "#                 a = pd.read_csv(\"../features/graph/%s_hits_%s_%s_%s_%s_%s.csv\" % (d1, d2, t, f, t, f))\n",
    "#                 df = df.merge(a, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  process_feature(train_x, valid_x, test_df):\n",
    "    result = []\n",
    "    drop_cols = ['id','label']\n",
    "    for df in [train_x, valid_x, test_df]:\n",
    "        result.append(df.drop(drop_cols, axis=1))\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def cv(df, num_folds, param, model_dir, stratified=True, debug=False):\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "    train_df = df[df.label.notnull()]\n",
    "    test_df = df[df.label.isnull()]\n",
    "#     seed = param[\"seed\"]\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=178)\n",
    "    else:\n",
    "        folds = KFold(n_splits= num_folds, shuffle=True, random_state=178)\n",
    "#     del param['seed']\n",
    "    oof_preds = np.zeros(train_df.shape[0])\n",
    "    all_test_preds = []    \n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df, train_df['label'])):\n",
    "        train_x, train_y = train_df.iloc[train_idx], train_df['label'].iloc[train_idx]\n",
    "        valid_x, valid_y = train_df.iloc[valid_idx], train_df['label'].iloc[valid_idx]\n",
    "        fold_preds = test_df[[\"id\"]]\n",
    "        \n",
    "        train_x, valid_x, test = process_feature(train_x, valid_x, test_df)\n",
    "        if n_fold == 0:\n",
    "            print(train_x.shape, valid_x.shape, test.shape)\n",
    "        \n",
    "        train_data = lgb.Dataset(train_x, label=train_y)\n",
    "        validation_data = lgb.Dataset(valid_x, label=valid_y)\n",
    "\n",
    "        clf=lgb.train(params,\n",
    "                      train_data,\n",
    "                      num_boost_round=10000,\n",
    "                      valid_sets=[train_data, validation_data],\n",
    "                      valid_names=[\"train\", \"valid\"],\n",
    "                      early_stopping_rounds=100,\n",
    "                      verbose_eval=100)\n",
    "\n",
    "        valid_preds = clf.predict(valid_x, num_iteration=clf.best_iteration)\n",
    "        test_preds = clf.predict(test, num_iteration=clf.best_iteration)\n",
    "\n",
    "        fold_preds['prob'] = test_preds\n",
    "        fold_preds['fold_id'] = n_fold + 1\n",
    "        all_test_preds.append(fold_preds)\n",
    "        \n",
    "        oof_preds[valid_idx] = valid_preds\n",
    "        \n",
    "        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, valid_preds)))\n",
    "        \n",
    "        del clf, train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "    full_auc = roc_auc_score(train_df['label'], oof_preds)\n",
    "    print('Full AUC score %.6f' % full_auc)\n",
    "    \n",
    "    if not debug:\n",
    "        train_df[\"prob\"] = oof_preds\n",
    "        train_df[['id', 'prob']].to_csv(model_dir + \"pred_train.csv\", index= False)\n",
    "\n",
    "        all_test_preds = pd.concat(all_test_preds, axis=0)\n",
    "        all_test_preds.to_csv(model_dir + \"all_test_preds.csv\", index=False)\n",
    "        \n",
    "        sub = pd.DataFrame()\n",
    "        sub['id'] = all_test_preds.id.unique()\n",
    "        sub.set_index(\"id\", inplace=True)\n",
    "        sub[\"prob\"] = all_test_preds.groupby(\"id\").prob.mean()\n",
    "        sub.reset_index().to_csv(model_dir + \"sub.txt\", index=False)\n",
    "    return full_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.path.exists(\"../model_output/lgb_628\"):\n",
    "    for root, dirs, files in os.walk(\"../model_output/lgb_628\", topdown=False):\n",
    "        for name in files:\n",
    "            os.remove(os.path.join(root, name))\n",
    "        for name in dirs:\n",
    "            os.rmdir(os.path.join(root, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15166, 628) (3793, 628) (6000, 628)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.829538\tvalid's auc: 0.671127\n",
      "[200]\ttrain's auc: 0.887853\tvalid's auc: 0.680413\n",
      "[300]\ttrain's auc: 0.916058\tvalid's auc: 0.687598\n",
      "[400]\ttrain's auc: 0.934874\tvalid's auc: 0.694527\n",
      "[500]\ttrain's auc: 0.949503\tvalid's auc: 0.698456\n",
      "[600]\ttrain's auc: 0.960076\tvalid's auc: 0.698174\n",
      "[700]\ttrain's auc: 0.96821\tvalid's auc: 0.699987\n",
      "[800]\ttrain's auc: 0.974461\tvalid's auc: 0.702842\n",
      "[900]\ttrain's auc: 0.979065\tvalid's auc: 0.70273\n",
      "Early stopping, best iteration is:\n",
      "[844]\ttrain's auc: 0.977473\tvalid's auc: 0.703952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/LAB/yanhao/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/LAB/yanhao/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1 AUC : 0.703952\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.827365\tvalid's auc: 0.659781\n",
      "[200]\ttrain's auc: 0.872074\tvalid's auc: 0.677238\n",
      "[300]\ttrain's auc: 0.894324\tvalid's auc: 0.679679\n",
      "[400]\ttrain's auc: 0.90377\tvalid's auc: 0.683439\n",
      "[500]\ttrain's auc: 0.921468\tvalid's auc: 0.687672\n",
      "[600]\ttrain's auc: 0.937144\tvalid's auc: 0.68994\n",
      "[700]\ttrain's auc: 0.94378\tvalid's auc: 0.688799\n",
      "Early stopping, best iteration is:\n",
      "[622]\ttrain's auc: 0.93869\tvalid's auc: 0.690367\n",
      "Fold  2 AUC : 0.690367\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.829686\tvalid's auc: 0.654232\n",
      "[200]\ttrain's auc: 0.887818\tvalid's auc: 0.680822\n",
      "[300]\ttrain's auc: 0.918028\tvalid's auc: 0.6956\n",
      "[400]\ttrain's auc: 0.936948\tvalid's auc: 0.703047\n",
      "[500]\ttrain's auc: 0.95092\tvalid's auc: 0.70509\n",
      "[600]\ttrain's auc: 0.96105\tvalid's auc: 0.706101\n",
      "Early stopping, best iteration is:\n",
      "[538]\ttrain's auc: 0.955431\tvalid's auc: 0.707104\n",
      "Fold  3 AUC : 0.707104\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.835266\tvalid's auc: 0.663834\n",
      "[200]\ttrain's auc: 0.889153\tvalid's auc: 0.683587\n",
      "[300]\ttrain's auc: 0.918983\tvalid's auc: 0.691011\n",
      "[400]\ttrain's auc: 0.939194\tvalid's auc: 0.693224\n",
      "Early stopping, best iteration is:\n",
      "[382]\ttrain's auc: 0.935494\tvalid's auc: 0.694045\n",
      "Fold  4 AUC : 0.694045\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.834919\tvalid's auc: 0.657257\n",
      "[200]\ttrain's auc: 0.888433\tvalid's auc: 0.676133\n",
      "[300]\ttrain's auc: 0.916749\tvalid's auc: 0.685662\n",
      "[400]\ttrain's auc: 0.936652\tvalid's auc: 0.690339\n",
      "[500]\ttrain's auc: 0.95104\tvalid's auc: 0.694201\n",
      "[600]\ttrain's auc: 0.961186\tvalid's auc: 0.698403\n",
      "[700]\ttrain's auc: 0.969061\tvalid's auc: 0.700262\n",
      "[800]\ttrain's auc: 0.975562\tvalid's auc: 0.702453\n",
      "Early stopping, best iteration is:\n",
      "[792]\ttrain's auc: 0.975123\tvalid's auc: 0.702752\n",
      "Fold  5 AUC : 0.702752\n",
      "Full AUC score 0.699215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/LAB/yanhao/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15166, 628) (3793, 628) (6000, 628)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.812497\tvalid's auc: 0.656298\n",
      "[200]\ttrain's auc: 0.871716\tvalid's auc: 0.682322\n",
      "[300]\ttrain's auc: 0.904092\tvalid's auc: 0.689614\n",
      "[400]\ttrain's auc: 0.925275\tvalid's auc: 0.692519\n",
      "[500]\ttrain's auc: 0.940944\tvalid's auc: 0.69604\n",
      "[600]\ttrain's auc: 0.952432\tvalid's auc: 0.698742\n",
      "[700]\ttrain's auc: 0.96102\tvalid's auc: 0.70014\n",
      "[800]\ttrain's auc: 0.967783\tvalid's auc: 0.700232\n",
      "Early stopping, best iteration is:\n",
      "[728]\ttrain's auc: 0.96356\tvalid's auc: 0.700927\n",
      "Fold  1 AUC : 0.700927\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.814596\tvalid's auc: 0.659916\n",
      "[200]\ttrain's auc: 0.874884\tvalid's auc: 0.68547\n",
      "[300]\ttrain's auc: 0.906171\tvalid's auc: 0.695856\n",
      "[400]\ttrain's auc: 0.926794\tvalid's auc: 0.703053\n",
      "[500]\ttrain's auc: 0.941884\tvalid's auc: 0.706601\n",
      "[600]\ttrain's auc: 0.953512\tvalid's auc: 0.707805\n",
      "[700]\ttrain's auc: 0.962144\tvalid's auc: 0.708421\n",
      "Early stopping, best iteration is:\n",
      "[621]\ttrain's auc: 0.955588\tvalid's auc: 0.709061\n",
      "Fold  2 AUC : 0.709061\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.818737\tvalid's auc: 0.657072\n",
      "[200]\ttrain's auc: 0.864893\tvalid's auc: 0.676078\n",
      "[300]\ttrain's auc: 0.884805\tvalid's auc: 0.686151\n",
      "[400]\ttrain's auc: 0.891981\tvalid's auc: 0.690953\n",
      "[500]\ttrain's auc: 0.910139\tvalid's auc: 0.696125\n",
      "[600]\ttrain's auc: 0.92723\tvalid's auc: 0.69591\n",
      "Early stopping, best iteration is:\n",
      "[571]\ttrain's auc: 0.923328\tvalid's auc: 0.697188\n",
      "Fold  3 AUC : 0.697188\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.824868\tvalid's auc: 0.66474\n",
      "[200]\ttrain's auc: 0.875915\tvalid's auc: 0.683958\n",
      "[300]\ttrain's auc: 0.90607\tvalid's auc: 0.691661\n",
      "[400]\ttrain's auc: 0.927136\tvalid's auc: 0.695856\n",
      "[500]\ttrain's auc: 0.942737\tvalid's auc: 0.697929\n",
      "Early stopping, best iteration is:\n",
      "[476]\ttrain's auc: 0.938757\tvalid's auc: 0.699008\n",
      "Fold  4 AUC : 0.699008\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.83414\tvalid's auc: 0.659843\n",
      "[200]\ttrain's auc: 0.879406\tvalid's auc: 0.670844\n",
      "[300]\ttrain's auc: 0.908543\tvalid's auc: 0.675661\n",
      "[400]\ttrain's auc: 0.927814\tvalid's auc: 0.683245\n",
      "[500]\ttrain's auc: 0.943484\tvalid's auc: 0.687167\n",
      "[600]\ttrain's auc: 0.954337\tvalid's auc: 0.688606\n",
      "[700]\ttrain's auc: 0.96282\tvalid's auc: 0.691132\n",
      "[800]\ttrain's auc: 0.969746\tvalid's auc: 0.693175\n",
      "[900]\ttrain's auc: 0.974808\tvalid's auc: 0.694221\n",
      "[1000]\ttrain's auc: 0.979192\tvalid's auc: 0.694444\n",
      "Early stopping, best iteration is:\n",
      "[983]\ttrain's auc: 0.978483\tvalid's auc: 0.694726\n",
      "Fold  5 AUC : 0.694726\n",
      "Full AUC score 0.699417\n",
      "(15166, 628) (3793, 628) (6000, 628)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.84637\tvalid's auc: 0.662801\n",
      "[200]\ttrain's auc: 0.89705\tvalid's auc: 0.682192\n",
      "[300]\ttrain's auc: 0.927744\tvalid's auc: 0.689095\n",
      "[400]\ttrain's auc: 0.947178\tvalid's auc: 0.692701\n",
      "[500]\ttrain's auc: 0.961141\tvalid's auc: 0.694813\n",
      "[600]\ttrain's auc: 0.971198\tvalid's auc: 0.696552\n",
      "[700]\ttrain's auc: 0.978446\tvalid's auc: 0.697283\n",
      "Early stopping, best iteration is:\n",
      "[625]\ttrain's auc: 0.97327\tvalid's auc: 0.697724\n",
      "Fold  1 AUC : 0.697724\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.841724\tvalid's auc: 0.635287\n",
      "[200]\ttrain's auc: 0.892808\tvalid's auc: 0.653063\n",
      "[300]\ttrain's auc: 0.924723\tvalid's auc: 0.662963\n",
      "[400]\ttrain's auc: 0.945786\tvalid's auc: 0.668305\n",
      "[500]\ttrain's auc: 0.960328\tvalid's auc: 0.670711\n",
      "[600]\ttrain's auc: 0.971143\tvalid's auc: 0.673196\n",
      "[700]\ttrain's auc: 0.978636\tvalid's auc: 0.675295\n",
      "[800]\ttrain's auc: 0.984214\tvalid's auc: 0.676438\n",
      "[900]\ttrain's auc: 0.987895\tvalid's auc: 0.675473\n",
      "Early stopping, best iteration is:\n",
      "[812]\ttrain's auc: 0.984803\tvalid's auc: 0.676659\n",
      "Fold  2 AUC : 0.676659\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.849368\tvalid's auc: 0.649499\n",
      "[200]\ttrain's auc: 0.896926\tvalid's auc: 0.673787\n",
      "[300]\ttrain's auc: 0.927009\tvalid's auc: 0.687049\n",
      "[400]\ttrain's auc: 0.946974\tvalid's auc: 0.694604\n",
      "[500]\ttrain's auc: 0.961684\tvalid's auc: 0.697552\n",
      "[600]\ttrain's auc: 0.971896\tvalid's auc: 0.700972\n",
      "[700]\ttrain's auc: 0.978967\tvalid's auc: 0.70286\n",
      "[800]\ttrain's auc: 0.984116\tvalid's auc: 0.704122\n",
      "[900]\ttrain's auc: 0.987976\tvalid's auc: 0.704753\n",
      "Early stopping, best iteration is:\n",
      "[868]\ttrain's auc: 0.986835\tvalid's auc: 0.705553\n",
      "Fold  3 AUC : 0.705553\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.800557\tvalid's auc: 0.657595\n",
      "Early stopping, best iteration is:\n",
      "[66]\ttrain's auc: 0.836861\tvalid's auc: 0.654733\n",
      "Fold  4 AUC : 0.654733\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.850035\tvalid's auc: 0.668804\n",
      "[200]\ttrain's auc: 0.89671\tvalid's auc: 0.686442\n",
      "[300]\ttrain's auc: 0.929404\tvalid's auc: 0.693055\n",
      "[400]\ttrain's auc: 0.949438\tvalid's auc: 0.696791\n",
      "[500]\ttrain's auc: 0.963587\tvalid's auc: 0.698722\n",
      "[600]\ttrain's auc: 0.974004\tvalid's auc: 0.700305\n",
      "Early stopping, best iteration is:\n",
      "[597]\ttrain's auc: 0.97366\tvalid's auc: 0.700441\n",
      "Fold  5 AUC : 0.700441\n",
      "Full AUC score 0.683104\n"
     ]
    }
   ],
   "source": [
    "params_list =[\n",
    " {'boosting_type': 'goss', 'colsample_bytree': 0.6864973162284662, 'learning_rate': 0.016509011940917025, 'max_bin': 490, 'metric': 'auc', 'min_child_weight': 13.879667947362398, 'num_leaves': 168, 'reg_alpha': 45.10181366931124, 'reg_lambda': 787.789656712201, 'subsample': 1.0, 'verbose': 1, 'seed': 936},\n",
    "#  {'boosting_type': 'goss', 'colsample_bytree': 0.659150320575524, 'learning_rate': 0.024664185229949905, 'max_bin': 500, 'metric': 'auc', 'min_child_weight': 8.553583281132703, 'num_leaves': 112, 'reg_alpha': 39.12187284284358, 'reg_lambda': 783.1029548688468, 'subsample': 1.0, 'verbose': 1, 'seed': 5890},\n",
    " {'boosting_type': 'goss', 'colsample_bytree': 0.6049610620049505, 'learning_rate': 0.015146997993879712, 'max_bin': 460, 'metric': 'auc', 'min_child_weight': 18.957938593688304, 'num_leaves': 179, 'reg_alpha': 43.38294598609216, 'reg_lambda': 877.1154326586918, 'subsample': 1.0, 'verbose': 1, 'seed': 9749},\n",
    " {'boosting_type': 'goss', 'colsample_bytree': 0.6026437299664836, 'learning_rate': 0.015085869032615395, 'max_bin': 440, 'metric': 'auc', 'min_child_weight': 19.869400918393595, 'num_leaves': 182, 'reg_alpha': 30.650834587953042, 'reg_lambda': 829.6945571384234, 'subsample': 1.0, 'verbose': 1, 'seed': 3377},\n",
    "#  {'boosting_type': 'goss', 'colsample_bytree': 0.6940924054812383, 'learning_rate': 0.02150946743907973, 'max_bin': 580, 'metric': 'auc', 'min_child_weight': 13.069288047260823, 'num_leaves': 141, 'reg_alpha': 44.27870167923196, 'reg_lambda': 781.768889061529, 'subsample': 1.0, 'verbose': 1, 'seed': 5088}\n",
    "             ]\n",
    "result = []\n",
    "for i, params in enumerate(params_list):\n",
    "    model_dir = \"../model_output/lgb_628/%d/\" % i\n",
    "    result.append(cv(df, 5, params, model_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69921548177432191, 0.69941683536599131, 0.6831041621046734]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
